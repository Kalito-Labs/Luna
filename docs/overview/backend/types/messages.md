# messages.ts - Chat Message Type Definitions

## Overview
`messages.ts` defines TypeScript interfaces for chat messages used throughout Kalito's AI conversation system. These types follow OpenAI-style message formats for compatibility with various LLM providers.

---

## Type Definitions

### Role (Lines 4)

```typescript
export type Role = 'system' | 'user' | 'assistant'
```

**Purpose:**
Defines who is "speaking" in a chat message.

---

#### Role Types

| Role | Who | Purpose | Example |
|------|-----|---------|---------|
| **system** | Application | Instructions, context, rules | "You are a helpful medical assistant" |
| **user** | Human | User's messages/questions | "What medications should I take?" |
| **assistant** | AI | AI's responses | "Let me help you with that..." |

---

#### system Role

```typescript
role: 'system'
```

**What it is:** Instructions and context for the AI

**Examples:**
```typescript
{
  role: 'system',
  content: 'You are a certified pharmacist assistant. Be professional and accurate.'
}

{
  role: 'system',
  content: 'Patient is allergic to Penicillin. Never recommend it.'
}

{
  role: 'system',
  content: 'Today is October 28, 2025. Patient name: John Doe.'
}
```

**Use cases:**
- Set AI personality/behavior
- Inject critical context (allergies, preferences)
- Provide current date/time
- Include semantic pins

**Position:** Typically first message(s) in conversation

---

#### user Role

```typescript
role: 'user'
```

**What it is:** Messages from the human user

**Examples:**
```typescript
{
  role: 'user',
  content: 'What are the side effects of Lisinopril?'
}

{
  role: 'user',
  content: 'Can my dad take ibuprofen with his blood pressure medication?'
}
```

**Use cases:**
- User questions
- User commands
- User feedback

---

#### assistant Role

```typescript
role: 'assistant'
```

**What it is:** Messages from the AI model

**Examples:**
```typescript
{
  role: 'assistant',
  content: 'Lisinopril is an ACE inhibitor. Common side effects include dry cough, dizziness, and headache.'
}

{
  role: 'assistant',
  content: "I'd recommend checking with your doctor before combining ibuprofen with blood pressure medication."
}
```

**Use cases:**
- AI responses
- AI clarifying questions
- AI acknowledgments

---

### Conversation Flow Example

```typescript
const conversation = [
  {
    role: 'system',
    content: 'You are a helpful eldercare assistant.'
  },
  {
    role: 'user',
    content: 'My dad has diabetes'
  },
  {
    role: 'assistant',
    content: 'I understand. What type of diabetes does he have?'
  },
  {
    role: 'user',
    content: 'Type 2'
  },
  {
    role: 'assistant',
    content: 'Type 2 diabetes is manageable with medication, diet, and exercise...'
  }
]
```

---

## Chat Message Types

### ChatMessage (Lines 9-12)

```typescript
export interface ChatMessage {
  role: Role
  content: string
}
```

**Purpose:**
Minimal message structure for LLM API requests (OpenAI-compatible format).

---

#### Property: role
```typescript
role: Role
```

**What it is:** Who is speaking (system, user, or assistant)

**Example:**
```typescript
role: 'user'
```

---

#### Property: content
```typescript
content: string
```

**What it is:** The message text

**Example:**
```typescript
content: 'What medications should I take with food?'
```

---

#### Complete ChatMessage Example

```typescript
const message: ChatMessage = {
  role: 'user',
  content: 'What are the symptoms of low blood sugar?'
}

// Send to LLM
const response = await openai.chat.completions.create({
  model: 'gpt-4',
  messages: [
    { role: 'system', content: 'You are a medical assistant' },
    message  // ← ChatMessage fits directly
  ]
})
```

---

### Message (Lines 17-22)

```typescript
export interface Message {
  id?: string
  role: Role
  text: string
  timestamp?: string
}
```

**Purpose:**
Extended message format for UI/database with additional metadata.

---

#### Property: id
```typescript
id?: string
```

**What it is:** Optional unique identifier for the message

**Example:**
```typescript
id: '1698501234567-abc123'  // Generated by generateId()
```

**Use cases:**
- Database primary key
- Referencing specific messages
- Editing/deleting messages
- Source tracking for semantic pins

---

#### Property: role
```typescript
role: Role
```

**What it is:** Same as ChatMessage (system, user, assistant)

---

#### Property: text
```typescript
text: string
```

**What it is:** The message content

**Note:** Called `text` instead of `content` for UI clarity

**Example:**
```typescript
text: 'How often should I check blood glucose?'
```

---

#### Property: timestamp
```typescript
timestamp?: string
```

**What it is:** When the message was created (ISO 8601 format)

**Example:**
```typescript
timestamp: '2025-10-28T10:30:45.123Z'
```

**Use cases:**
- Display message time in UI
- Sort messages chronologically
- Calculate conversation duration
- Audit trails

---

#### Complete Message Example

```typescript
const message: Message = {
  id: '1698501234567-abc123',
  role: 'user',
  text: 'Should my dad take Metformin with breakfast or dinner?',
  timestamp: '2025-10-28T10:30:45.123Z'
}
```

---

## ChatMessage vs Message

### When to Use Each

**Use ChatMessage:**
- ✅ Sending to LLM APIs (OpenAI, Anthropic, etc.)
- ✅ Minimal payload (no extra metadata)
- ✅ Direct API compatibility

**Use Message:**
- ✅ Storing in database
- ✅ Displaying in UI
- ✅ Tracking metadata (id, timestamp)
- ✅ Message history management

---

### Conversion Between Types

```typescript
// Message → ChatMessage (for LLM API)
function toChatMessage(message: Message): ChatMessage {
  return {
    role: message.role,
    content: message.text
  }
}

// ChatMessage → Message (from LLM response)
function toMessage(chatMessage: ChatMessage): Message {
  return {
    id: generateId(),
    role: chatMessage.role,
    text: chatMessage.content,
    timestamp: new Date().toISOString()
  }
}
```

**Usage:**
```typescript
// Fetch messages from database
const messages: Message[] = await db.getMessages(session_id)

// Convert for LLM
const chatMessages: ChatMessage[] = messages.map(toChatMessage)

// Send to LLM
const response = await llm.generate({ messages: chatMessages })

// Convert response back to Message
const assistantMessage: Message = toMessage({
  role: 'assistant',
  content: response.reply
})

// Save to database
await db.saveMessage(assistantMessage)
```

---

## Integration Patterns

### Pattern 1: Storing Messages

```typescript
// Backend: Save message to database
async function saveMessage(sessionId: string, role: Role, text: string) {
  const message: Message = {
    id: generateId(),
    role,
    text,
    timestamp: new Date().toISOString()
  }
  
  db.prepare(`
    INSERT INTO messages (id, session_id, role, text, timestamp)
    VALUES (?, ?, ?, ?, ?)
  `).run(message.id, sessionId, message.role, message.text, message.timestamp)
  
  return message
}
```

### Pattern 2: Building Context

```typescript
// Backend: Build LLM context from stored messages
async function buildContext(sessionId: string): Promise<ChatMessage[]> {
  const messages: Message[] = db.prepare(`
    SELECT * FROM messages 
    WHERE session_id = ? 
    ORDER BY timestamp ASC
  `).all(sessionId)
  
  // Add system message
  const systemMessage: ChatMessage = {
    role: 'system',
    content: 'You are a helpful eldercare assistant.'
  }
  
  // Convert stored messages
  const chatMessages: ChatMessage[] = messages.map(m => ({
    role: m.role,
    content: m.text
  }))
  
  return [systemMessage, ...chatMessages]
}
```

### Pattern 3: Frontend Display

```typescript
// Frontend: Display messages in UI
function MessageList({ messages }: { messages: Message[] }) {
  return (
    <div>
      {messages.map(message => (
        <div key={message.id} className={message.role}>
          <span className="timestamp">
            {new Date(message.timestamp).toLocaleTimeString()}
          </span>
          <span className="sender">{message.role}</span>
          <p>{message.text}</p>
        </div>
      ))}
    </div>
  )
}
```

### Pattern 4: Complete Chat Flow

```typescript
// Complete flow: User sends message, AI responds

async function handleUserMessage(sessionId: string, userText: string) {
  // 1. Save user message
  const userMessage = await saveMessage(sessionId, 'user', userText)
  
  // 2. Build context
  const context: ChatMessage[] = await buildContext(sessionId)
  
  // 3. Send to LLM
  const response = await llm.generate({ messages: context })
  
  // 4. Save AI response
  const assistantMessage = await saveMessage(
    sessionId,
    'assistant',
    response.reply
  )
  
  // 5. Return both messages
  return {
    userMessage,
    assistantMessage
  }
}
```

---

## Database Schema

### messages Table

```sql
CREATE TABLE messages (
  id TEXT PRIMARY KEY,
  session_id TEXT NOT NULL,
  role TEXT NOT NULL,  -- 'system', 'user', 'assistant'
  text TEXT NOT NULL,
  model_id TEXT,
  token_usage INTEGER,
  timestamp TEXT NOT NULL,
  FOREIGN KEY (session_id) REFERENCES sessions(id) ON DELETE CASCADE
);

CREATE INDEX idx_messages_session_id ON messages(session_id);
CREATE INDEX idx_messages_timestamp ON messages(timestamp);
```

**Additional fields (beyond Message type):**
- `model_id`: Which AI model generated the response
- `token_usage`: Tokens consumed (for billing/analytics)

---

## Best Practices

### 1. Always Include System Messages
```typescript
// ✅ Good
const messages: ChatMessage[] = [
  { role: 'system', content: 'You are a helpful assistant.' },
  { role: 'user', content: 'Hello' }
]

// ❌ Bad - missing system message
const messages: ChatMessage[] = [
  { role: 'user', content: 'Hello' }
]
```

### 2. Alternate user/assistant Roles
```typescript
// ✅ Good - alternating pattern
[
  { role: 'system', content: '...' },
  { role: 'user', content: 'Question 1' },
  { role: 'assistant', content: 'Answer 1' },
  { role: 'user', content: 'Question 2' },
  { role: 'assistant', content: 'Answer 2' }
]

// ❌ Bad - consecutive user messages
[
  { role: 'user', content: 'Question 1' },
  { role: 'user', content: 'Question 2' },  // Should be combined
  { role: 'assistant', content: 'Answer' }
]
```

### 3. Sanitize User Input
```typescript
// ✅ Good
function createUserMessage(text: string): Message {
  return {
    id: generateId(),
    role: 'user',
    text: text.trim().slice(0, 4000),  // Trim & limit length
    timestamp: new Date().toISOString()
  }
}

// ❌ Bad - no validation
function createUserMessage(text: string): Message {
  return { role: 'user', text }
}
```

### 4. Include Timestamps
```typescript
// ✅ Good
const message: Message = {
  id: generateId(),
  role: 'user',
  text: 'Hello',
  timestamp: new Date().toISOString()
}

// ❌ Bad - missing timestamp
const message: Message = {
  role: 'user',
  text: 'Hello'
}
```

### 5. Type-Safe Role Handling
```typescript
// ✅ Good - type-safe
function isUserMessage(message: Message): message is Message & { role: 'user' } {
  return message.role === 'user'
}

const userMessages = messages.filter(isUserMessage)
// TypeScript knows role is 'user'

// ❌ Bad - string comparison
const userMessages = messages.filter(m => m.role == 'user')  // Typo risk
```

---

## OpenAI Compatibility

### Direct Compatibility

Kalito's `ChatMessage` type is **directly compatible** with OpenAI's API:

```typescript
import OpenAI from 'openai'

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })

const messages: ChatMessage[] = [
  { role: 'system', content: 'You are a helpful assistant.' },
  { role: 'user', content: 'What is eldercare?' }
]

// ✅ Works directly - no conversion needed
const completion = await openai.chat.completions.create({
  model: 'gpt-4',
  messages: messages  // ChatMessage[] fits OpenAI type
})
```

### Extended OpenAI Format

OpenAI supports additional fields (ignored if not needed):

```typescript
// OpenAI's full message type
interface OpenAIChatMessage {
  role: 'system' | 'user' | 'assistant' | 'function' | 'tool'
  content: string | null
  name?: string
  function_call?: { name: string; arguments: string }
  tool_calls?: Array<{ id: string; type: string; function: { name: string; arguments: string } }>
}

// Kalito's ChatMessage is a subset (always compatible)
```

---

## Multi-Provider Support

### Anthropic (Claude)

```typescript
// Anthropic uses same format
import Anthropic from '@anthropic-ai/sdk'

const anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY })

const messages: ChatMessage[] = [
  { role: 'user', content: 'Hello' }
]

// ✅ Works with slight adaptation
const response = await anthropic.messages.create({
  model: 'claude-3-opus-20240229',
  system: 'You are a helpful assistant.',  // System separate
  messages: messages.map(m => ({
    role: m.role === 'user' ? 'user' : 'assistant',  // No 'system' in messages
    content: m.content
  }))
})
```

### Ollama (Local)

```typescript
// Ollama uses same format
const messages: ChatMessage[] = [
  { role: 'system', content: 'You are helpful' },
  { role: 'user', content: 'Hello' }
]

// ✅ Direct compatibility
const response = await fetch('http://localhost:11434/api/chat', {
  method: 'POST',
  body: JSON.stringify({
    model: 'llama2',
    messages: messages  // Same format
  })
})
```

---

## Migration Notes

### AgentRequest Moved

**Note in file (Lines 24-25):**
```typescript
// AgentRequest moved to agent.ts to avoid duplication
// Use AgentRequest from './agent' instead
```

**Why:** Previously, `AgentRequest` was defined here but caused duplication. Now centralized in `agent.ts`.

**Migration:**
```typescript
// ❌ Old
import { AgentRequest } from './types/messages'

// ✅ New
import { AgentRequest } from './types/agent'
```

---

## Summary

**messages.ts defines two core chat message types:**

### Role
- **Type-safe enum** ('system' | 'user' | 'assistant')
- **OpenAI-compatible** format

### ChatMessage
- **Minimal format** for LLM APIs
- **Direct compatibility** with OpenAI, Anthropic, Ollama
- **Fields**: role, content

### Message
- **Extended format** for UI/database
- **Additional metadata**: id, timestamp
- **Fields**: id?, role, text, timestamp?

**Key benefits:**
- Type safety (no typos like 'usr' instead of 'user')
- OpenAI API compatibility
- Clean separation (minimal for API, extended for storage)
- Multi-provider support

**Common pattern:**
```typescript
// Store: Message (with id, timestamp)
// Send to LLM: ChatMessage (minimal)
// Receive from LLM: ChatMessage
// Convert back: Message (add id, timestamp)
```
